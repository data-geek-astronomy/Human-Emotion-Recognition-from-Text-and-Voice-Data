# Human-Emotion-Recognition-from-Text-and-Voice-Data

# Human Emotion Recognition from Text and Voice Data

This project is a cutting-edge system designed to recognize human emotions from both textual and voice data. Utilizing advanced technologies such as deep learning, Natural Language Processing (NLP), and audio processing, the system boasts an impressive accuracy of 87%. Its applications are vast, including enhancements in human-computer interaction, customer service, and mental health support systems.

## Features
- Emotion recognition from text data using BERT for contextualized embeddings.
- Voice data processing with Mel-Frequency Cepstral Coefficients (MFCCs), CNNs, and RNNs.
- A unified LSTM and MLP-based model to integrate text and audio features.
- Evaluation metrics implementation: precision, F1-score, and accuracy.

## Installation
Ensure Python 3.x is installed on your system. Install the required dependencies using:

* pip install -r requirements.txt

Project Structure
* text_processing/: Code for processing text data with BERT.
* voice_processing/: Code for voice data processing and feature extraction.
* model/: LSTM and MLP model for emotion recognition.
* evaluation/: Code for model evaluation (precision, F1-score, accuracy).
* main.py: Main script to run the project.


## Usage
Execute the project with the following command:

python main.py


## Contributing
Contributions to this project are welcomed. Ensure that pull requests or changes are consistent with the existing code style and structure.
